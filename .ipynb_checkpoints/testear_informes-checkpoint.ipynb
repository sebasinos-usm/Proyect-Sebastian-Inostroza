{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baaf909-e71d-4743-addf-db584a59fe06",
   "metadata": {},
   "source": [
    "# TEST DEL PROYECTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e2b39f-7519-456b-89dc-7318cfb4c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo 'pipeline_naive_bayes.pkl' cargado exitosamente.\n",
      " Usando umbral de criticidad personalizado: 40%\n",
      "\n",
      " Encontrados 2 archivos PDF. Iniciando análisis...\n",
      "\n",
      "  - ADVERTENCIA: Marcadores de inicio/fin no encontrados. Se usará el texto completo.\n",
      "--------------------------------------------------\n",
      "Archivo: resultadoexamen (2).pdf\n",
      "  Resultado: No Crítico\n",
      "  Porcentaje de efectividad (confianza): 77.28%\n",
      "--------------------------------------------------\n",
      "  - ADVERTENCIA: Marcadores de inicio/fin no encontrados. Se usará el texto completo.\n",
      "--------------------------------------------------\n",
      "Archivo: resultadoexamen (3).pdf\n",
      "  Resultado: No Crítico\n",
      "  Porcentaje de efectividad (confianza): 77.12%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='nltk')\n",
    "\n",
    "def extraer_texto_de_pdf(ruta_pdf):\n",
    "    \"\"\"Extrae el texto de un archivo PDF preservando los bloques.\"\"\"\n",
    "    try:\n",
    "        with fitz.open(ruta_pdf) as doc:\n",
    "            texto_completo = \"\"\n",
    "            for pagina in doc:\n",
    "                bloques = pagina.get_text(\"blocks\", sort=True)\n",
    "                for b in bloques:\n",
    "                    texto_completo += b[4]\n",
    "        return texto_completo\n",
    "    except Exception as e:\n",
    "        print(f\"  - ERROR al leer el archivo {os.path.basename(ruta_pdf)}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extraer_cuerpo_informe(texto_completo):\n",
    "    \"\"\"\n",
    "    Aísla el cuerpo principal del informe de forma más flexible.\n",
    "    \"\"\"\n",
    "    # \\s* significa \"cero o más espacios en blanco\"\n",
    "    \n",
    "    # ▼▼▼ LÍNEAS MODIFICADAS ▼▼▼\n",
    "    marcador_inicio_primario = r\"\\\\bExamen\\\\s*:\" \n",
    "    marcador_inicio_secundario = r\"Fecha Examen\" # Esta es menos propensa a errores\n",
    "    marcador_fin_cuerpo = r\"Dr(\\\\(a\\\\))?\\\\s*\\\\.|\\\\bAtentamente\\\\b|\\\\bAtte\\\\.\\\\b\"\n",
    "\n",
    "    # --- El resto de la función no necesita cambios ---\n",
    "    match_inicio = re.search(marcador_inicio_primario, texto_completo, re.IGNORECASE)\n",
    "    if not match_inicio:\n",
    "        match_inicio = re.search(marcador_inicio_secundario, texto_completo, re.IGNORECASE)\n",
    "    \n",
    "    match_fin = re.search(marcador_fin_cuerpo, texto_completo, re.IGNORECASE)\n",
    "\n",
    "    if match_inicio and match_fin:\n",
    "        # Si encuentra los marcadores, la advertencia NO aparecerá\n",
    "        return texto_completo[match_inicio.start():match_fin.start()]\n",
    "    else:\n",
    "        # Esta advertencia aparecerá si aún así no los encuentra\n",
    "        print(f\"  - ADVERTENCIA: Marcadores de inicio/fin no encontrados. Se usará el texto completo.\")\n",
    "        return texto_completo\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Descargar stopwords solo si es necesario\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "    except LookupError:\n",
    "        print(\"Descargando 'stopwords' de NLTK...\")\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "    text = text.lower()\n",
    "    forma_nfd = unicodedata.normalize('NFD', text)\n",
    "    text = \"\".join([c for c in forma_nfd if not unicodedata.combining(c)])\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# ==============================================================================\n",
    "#    FUNCIÓN PRINCIPAL DE PREDICCIÓN\n",
    "# ==============================================================================\n",
    "\n",
    "def predecir_informe_pdf(ruta_pdf, modelo, umbral):\n",
    "    \"\"\"\n",
    "    Procesa un único archivo PDF y devuelve su clasificación y probabilidad.\n",
    "    \"\"\"\n",
    "    print(f\"----- Analizando el archivo: {os.path.basename(ruta_pdf)} -----\")\n",
    "    \n",
    "    # Paso 1: Extraer el texto crudo del PDF\n",
    "    texto_crudo = extraer_texto_de_pdf(ruta_pdf)\n",
    "    if not texto_crudo:\n",
    "        return \"Error\", 0.0, \"No se pudo extraer texto.\"\n",
    "        \n",
    "    # Esto te mostrará el texto exacto con todos sus espacios y saltos de línea.\n",
    "    print(\"\\n--- TEXTO CRUDO EXTRAÍDO (lo que ve el script) ---\\n\")\n",
    "    print(repr(texto_crudo)) # Usamos repr() para ver caracteres \"invisibles\" como \\n\n",
    "    print(\"\\n--- FIN DEL TEXTO CRUDO ---\\n\")\n",
    "    \n",
    "    # El resto del proceso continúa igual...\n",
    "    cuerpo_informe = extraer_cuerpo_informe(texto_crudo)\n",
    "    # ... (el resto de la función no cambia)\n",
    "\n",
    "    cuerpo_informe = extraer_cuerpo_informe(texto_crudo)\n",
    "    texto_limpio = preprocess_text(cuerpo_informe)\n",
    "    \n",
    "    # El pipeline espera una lista de textos\n",
    "    textos_a_predecir = [texto_limpio]\n",
    "    \n",
    "    # Obtener las probabilidades del modelo\n",
    "    probabilidades = modelo.predict_proba(textos_a_predecir)[0]\n",
    "    prob_critico = probabilidades[1] # Probabilidad de la clase \"Crítico\" (etiqueta 1)\n",
    "    \n",
    "    # Aplicar el umbral de decisión personalizado\n",
    "    if prob_critico >= umbral:\n",
    "        clasificacion_final = \"Crítico\"\n",
    "        efectividad = prob_critico\n",
    "    else:\n",
    "        clasificacion_final = \"No Crítico\"\n",
    "        efectividad = probabilidades[0] # Probabilidad de la clase \"No Crítico\"\n",
    "        \n",
    "    return clasificacion_final, efectividad, texto_limpio\n",
    "\n",
    "# ==============================================================================\n",
    "#  EJECUCIÓN DEL SCRIPT\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CONFIGURACIÓN ---\n",
    "    RUTA_MODELO = 'pipeline_naive_bayes.pkl'\n",
    "    CARPETA_PARA_TESTEAR = 'Informes_Para_Testear'\n",
    "    UMBRAL_CRITICIDAD = 0.4 # El umbral optimizado de tu proyecto\n",
    "\n",
    "    # Cargar el modelo\n",
    "    try:\n",
    "        modelo_cargado = joblib.load(RUTA_MODELO)\n",
    "        print(f\" Modelo '{RUTA_MODELO}' cargado exitosamente.\")\n",
    "        print(f\" Usando umbral de criticidad personalizado: {UMBRAL_CRITICIDAD:.0%}\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\" ERROR: No se encontró el archivo del modelo '{RUTA_MODELO}'.\")\n",
    "        print(\"Asegúrate de que el archivo del modelo esté en la misma carpeta que este script.\")\n",
    "        modelo_cargado = None\n",
    "    \n",
    "    # Procesar la carpeta de informes\n",
    "    if modelo_cargado:\n",
    "        if not os.path.isdir(CARPETA_PARA_TESTEAR):\n",
    "            print(f\" ERROR: La carpeta '{CARPETA_PARA_TESTEAR}' no existe.\")\n",
    "            print(\"Por favor, créala y coloca los PDFs que deseas analizar dentro.\")\n",
    "        else:\n",
    "            archivos_pdf = [f for f in os.listdir(CARPETA_PARA_TESTEAR) if f.lower().endswith('.pdf')]\n",
    "            \n",
    "            if not archivos_pdf:\n",
    "                print(f\" No se encontraron archivos PDF para analizar en la carpeta '{CARPETA_PARA_TESTEAR}'.\")\n",
    "            else:\n",
    "                print(f\" Encontrados {len(archivos_pdf)} archivos PDF. Iniciando análisis...\\n\")\n",
    "                \n",
    "                for nombre_archivo in archivos_pdf:\n",
    "                    ruta_completa_pdf = os.path.join(CARPETA_PARA_TESTEAR, nombre_archivo)\n",
    "                    \n",
    "                    resultado, efectividad, _ = predecir_informe_pdf(ruta_completa_pdf, modelo_cargado, UMBRAL_CRITICIDAD)\n",
    "                    \n",
    "                    print(\"-\" * 50)\n",
    "                    print(f\"Archivo: {nombre_archivo}\")\n",
    "                    print(f\"  Resultado: {resultado}\")\n",
    "                    print(f\"  Porcentaje de efectividad (confianza): {efectividad:.2%}\")\n",
    "                    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078b351-f024-4096-ae3d-19f2c74c695f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
